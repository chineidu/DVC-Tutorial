{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from feature_engine.transformation import YeoJohnsonTransformer\n",
    "from feature_engine.imputation import MeanMedianImputer\n",
    "from feature_engine.imputation import CategoricalImputer\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "from feature_engine.encoding import RareLabelEncoder\n",
    "from feature_engine.selection import DropFeatures\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Built-in library\n",
    "import itertools\n",
    "import re\n",
    "import json\n",
    "import logging\n",
    "import typing as tp\n",
    "\n",
    "\n",
    "# pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def set_up_logger(delim: str = \"::\") -> tp.Any:\n",
    "    \"\"\"This is used to create a basic logger.\"\"\"\n",
    "    format_ = f\"[%(levelname)s] {delim} %(asctime)s {delim} %(message)s\"\n",
    "    logging.basicConfig(level=logging.INFO, format=format_)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    return logger\n",
    "\n",
    "\n",
    "def load_data(*, filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"This is used to load data as a dataframe.\n",
    "\n",
    "    Params:\n",
    "        filepath (str): The filepath of the input data.\n",
    "\n",
    "    Returns:\n",
    "        df (pd.Dataframe): A DF containing the input data.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    logger.info(f\"Shape of df: {df.shape}\\n\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = set_up_logger()\n",
    "\n",
    "# Load data\n",
    "df = load_data(filepath=\"../data/titanic_train.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_manager import CastVariables\n",
    "\n",
    "cast_feats = CastVariables(features=[\"Pclass\", \"SibSp\", \"Parch\"])\n",
    "cast_feats.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "target = \"Survived\"\n",
    "test_size = 0.1\n",
    "random_state = 123\n",
    "\n",
    "\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=random_state\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into numerical and categorical variables\n",
    "num_vars = [*X_train.select_dtypes(exclude=\"O\").columns]\n",
    "cat_vars = [*X_train.select_dtypes(exclude=[\"int\", \"float\"]).columns]\n",
    "\n",
    "num_vars, cat_vars"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "num_vars_wf_na = [var for var in num_vars if X_train[var].isna().sum() > 0]\n",
    "\n",
    "# Percentage of missing values\n",
    "X_train[num_vars_wf_na].isna().mean().mul(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"Age\"].plot(kind=\"hist\")\n",
    "plt.title(\"Distribution of Age\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[num_vars].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing values in numerical variables\n",
    "mean_imputer = MeanMedianImputer(imputation_method=\"median\", variables=num_vars_wf_na)\n",
    "X_train = mean_imputer.fit_transform(X_train)\n",
    "X_test = mean_imputer.transform(X_test)\n",
    "\n",
    "# Verify\n",
    "X_train[num_vars_wf_na].isna().mean().mul(100), X_test[\n",
    "    num_vars_wf_na\n",
    "].isna().mean().mul(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Cardinality\n",
    "for var in num_vars:\n",
    "    uniq_vals = X_train[var].nunique()\n",
    "    print(f\"{var}: {uniq_vals} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the discrete variables\n",
    "thresh = 20\n",
    "discrete_vars = [var for var in num_vars if X_train[var].nunique() < thresh]\n",
    "\n",
    "num_vars = [*set(num_vars).difference(set(discrete_vars))]\n",
    "\n",
    "num_vars, discrete_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast to categorical\n",
    "X_train[discrete_vars] = X_train[discrete_vars].astype(str)\n",
    "X_test[discrete_vars] = X_test[discrete_vars].astype(str)\n",
    "\n",
    "\n",
    "# Check for `rare` labels\n",
    "for var in discrete_vars:\n",
    "    labels = X_train[var].value_counts(normalize=True).mul(100)\n",
    "    print(f\"{var}: \\n{labels} unique values\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Rare Labels\n",
    "rare_label_enc = RareLabelEncoder(tol=0.05, n_categories=5, variables=discrete_vars)\n",
    "X_train = rare_label_enc.fit_transform(X_train)\n",
    "X_test = rare_label_enc.transform(X_test)\n",
    "\n",
    "# Check for `rare` labels\n",
    "result = {}\n",
    "for var in discrete_vars:\n",
    "    labels = X_train[var].value_counts(normalize=True).mul(100)\n",
    "    result[var] = labels.to_dict()\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "for var in discrete_vars:\n",
    "    labels = X_test[var].value_counts(normalize=True).mul(100)\n",
    "    result[var] = labels.to_dict()\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the variables\n",
    "yea_johnson_transf = YeoJohnsonTransformer(variables=num_vars)\n",
    "X_train = yea_johnson_transf.fit_transform(X_train)\n",
    "X_test = yea_johnson_transf.transform(X_test)\n",
    "\n",
    "X_train.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "cat_vars_wf_na = [var for var in cat_vars if X_train[var].isna().sum() > 0]\n",
    "\n",
    "# Percentage of missing values\n",
    "X_train[cat_vars_wf_na].isna().mean().mul(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars = [\"Age\", \"Fare\"]  # Update vars\n",
    "\n",
    "# Drop variable(s)\n",
    "features_to_drop = [\"Cabin\", \"Name\", \"Ticket\", \"PassengerId\"]\n",
    "drop_feats = DropFeatures(features_to_drop=features_to_drop)\n",
    "\n",
    "X_train = drop_feats.fit_transform(X_train)\n",
    "X_test = drop_feats.transform(X_test)\n",
    "\n",
    "X_train.columns, X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = [*set(cat_vars).difference(set(features_to_drop))]\n",
    "\n",
    "cat_vars, features_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing values in categorical variables\n",
    "cat_vars_wf_na = [\"Embarked\"]\n",
    "cat_imputer = CategoricalImputer(imputation_method=\"frequent\", variables=cat_vars_wf_na)\n",
    "X_train = cat_imputer.fit_transform(X_train)\n",
    "X_test = cat_imputer.transform(X_test)\n",
    "\n",
    "# Verify\n",
    "X_train[cat_vars_wf_na].isna().mean().mul(100), X_test[\n",
    "    cat_vars_wf_na\n",
    "].isna().mean().mul(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[cat_vars + discrete_vars].info()\n",
    "\n",
    "cat_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Categorical Variables\n",
    "cat_enc = OrdinalEncoder(encoding_method=\"ordered\", variables=cat_vars + discrete_vars)\n",
    "X_train = cat_enc.fit_transform(X_train, y_train)\n",
    "X_test = cat_enc.transform(X_test)\n",
    "\n",
    "# Verify\n",
    "X_train[num_vars + cat_vars + discrete_vars].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the  variables\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Verify\n",
    "X_train[:5], X_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20aa346decfc1ab04ebf7e6c0e8a683073c52e14d9117eeba2bbc71e06a5cee4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
